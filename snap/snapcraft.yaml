name: mistral-7b-instruct
base: core24
version: "v0.3+0.0.1"
summary: Mistral 7B Instruct
description: |
  This snap installs an optimized environment for inference with the
  mistral-7b-instruct LLM.


grade: devel
confinement: devmode

compression: lzo

# environment:
#   SNAP_COMPONENTS: /snap/$SNAP_INSTANCE_NAME/components/$SNAP_REVISION

parts:
  local:
    source: snap/local
    plugin: dump
  
  mistral-inference:
    source: inference/mistral-inference/engine
    plugin: python
    python-packages:
      - mistral-inference==1.5.0
    organize:
      "*": (component/mistral-inference)
  
  mistral-cli:
    source: inference/mistral-inference/cli
    plugin: dump
    organize:
      "*": (component/mistral-inference)/bin/

  model-mistral-7b-instruct:
    source: mistral-7B-Instruct-v0.3.tar
    plugin: dump
    organize:
      "*": (component/model-mistral-7b-instruct)
    override-build: |
      craftctl default
      chmod 664 $CRAFT_PART_INSTALL/consolidated.safetensors

components:
  mistral-inference:
    type: test
    summary: Mistral Inference
    description: Inference Engine from Mistral
    version: "1.5.0" # should match the python package
  model-mistral-7b-instruct:
    type: test
    summary: Mistral 7B Instruct
    description: Model with safetensors, params, and tokenizer
    version: "v0.3" # should be consistent with the package version

apps:
  chat:
    command: bin/chat.sh
    plugs:
      - opengl

plugs:
  graphics:
    interface: content
    target: $SNAP/graphics
